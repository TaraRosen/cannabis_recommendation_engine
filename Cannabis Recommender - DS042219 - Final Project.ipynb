{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import pandas\n",
    "import urllib\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException, WebDriverException\n",
    "\n",
    "import csv\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A quick look at https://www.leafly.com/explore/page-61/sort-alpha shows \n",
    "#that this is the last page of strains\n",
    "pages = 61 \n",
    "websites = []\n",
    "strain_names = []\n",
    "\n",
    "for i in range(pages+1):\n",
    "    page_url = \"https://www.leafly.com/explore/page-\"+str(i)+\"/sort-alpha\"\n",
    "    html = requests.get(page_url).text\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    urls = soup.findAll(\"a\",{\"class\":\"ga_Explore_Strain_Tile\"})\n",
    "        \n",
    "    for url in urls:\n",
    "        strain_name = url.get('href')\n",
    "        strain_names.append(strain_name)\n",
    "        website = (\"https://www.leafly.com\" + strain_name)\n",
    "        websites.append(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create url df\n",
    "url_df = pd.DataFrame(websites, columns = ['url']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create url csv\n",
    "url_df.to_csv('urls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create strain_names csv\n",
    "strains_df = pd.DataFrame(strain_names, columns = ['strain_name']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create strain_names csv\n",
    "strains_df.to_csv('strains.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse strain_name:\n",
    "\n",
    "parsed =[]\n",
    "for words in strains_df['strain_name']:\n",
    "    parse = re.findall(r\"[\\w']+\", words)\n",
    "    parsed.append(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hybrid', '100', 'og'],\n",
       " ['hybrid', '98', 'white', 'widow'],\n",
       " ['sativa', '1024'],\n",
       " ['hybrid', '12', 'year', 'og'],\n",
       " ['hybrid', '13', 'dawgs'],\n",
       " ['hybrid', '22'],\n",
       " ['hybrid', '24k', 'gold'],\n",
       " ['indica', '3', 'bears', 'og'],\n",
       " ['hybrid', '100', 'og'],\n",
       " ['hybrid', '98', 'white', 'widow']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#create name and strain df\n",
    "\n",
    "strain_type_df = pd.DataFrame(parsed, columns = ['strain', 'name1', 'name2',\n",
    "                                    'name3', 'name4', 'name5', 'name6']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#drop last 5 columns - just fillers\n",
    "\n",
    "strain_type_df.drop(df.tail(5).index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge name columns\n",
    "\n",
    "strain_type_df['name'] = strain_type_df[strain_type_df.columns[1:]].apply(\n",
    "    lambda x: ' '.join(x.dropna().astype(str)),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns\n",
    "\n",
    "strain_type_df.drop(['name1', 'name2', 'name3', 'name4', 'name5', 'name6'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "strain_type_df.to_csv('strain_type.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2958"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of duplicates\n",
    "\n",
    "df['name'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_df['url'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://www.leafly.com/hybrid/100-og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.leafly.com/hybrid/98-white-widow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.leafly.com/sativa/1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.leafly.com/hybrid/12-year-og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.leafly.com/hybrid/13-dawgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>https://www.leafly.com/hybrid/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>https://www.leafly.com/hybrid/24k-gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>https://www.leafly.com/indica/3-bears-og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>https://www.leafly.com/hybrid/3-kings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>https://www.leafly.com/indica/303-og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18</td>\n",
       "      <td>https://www.leafly.com/sativa/3d-cbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19</td>\n",
       "      <td>https://www.leafly.com/indica/3x-crazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>https://www.leafly.com/hybrid/3rd-coast-panama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21</td>\n",
       "      <td>https://www.leafly.com/hybrid/501st-og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "      <td>https://www.leafly.com/hybrid/541-kush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>https://www.leafly.com/indica/5th-element</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>https://www.leafly.com/hybrid/707-headband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>https://www.leafly.com/hybrid/707-truthband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>https://www.leafly.com/indica/8-ball-kush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>27</td>\n",
       "      <td>https://www.leafly.com/indica/818-og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>28</td>\n",
       "      <td>https://www.leafly.com/indica/831-og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>29</td>\n",
       "      <td>https://www.leafly.com/hybrid/840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>30</td>\n",
       "      <td>https://www.leafly.com/indica/9-pound-hammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>31</td>\n",
       "      <td>https://www.leafly.com/indica/91-krypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>32</td>\n",
       "      <td>https://www.leafly.com/hybrid/92-og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>33</td>\n",
       "      <td>https://www.leafly.com/indica/999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>34</td>\n",
       "      <td>https://www.leafly.com/indica/a-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>35</td>\n",
       "      <td>https://www.leafly.com/hybrid/a-dub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>36</td>\n",
       "      <td>https://www.leafly.com/hybrid/a-train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>37</td>\n",
       "      <td>https://www.leafly.com/hybrid/acdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>3422</td>\n",
       "      <td>https://www.leafly.com/indica/xxx-og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>3423</td>\n",
       "      <td>https://www.leafly.com/sativa/xanadu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>3432</td>\n",
       "      <td>https://www.leafly.com/sativa/y-griega</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>3433</td>\n",
       "      <td>https://www.leafly.com/hybrid/yem-og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>3434</td>\n",
       "      <td>https://www.leafly.com/indica/yeti-og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>3435</td>\n",
       "      <td>https://www.leafly.com/indica/yoda-og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>3436</td>\n",
       "      <td>https://www.leafly.com/indica/yodas-brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2940</th>\n",
       "      <td>3437</td>\n",
       "      <td>https://www.leafly.com/hybrid/yogi-diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>3438</td>\n",
       "      <td>https://www.leafly.com/indica/yolo-berry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942</th>\n",
       "      <td>3439</td>\n",
       "      <td>https://www.leafly.com/indica/yumboldt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>3440</td>\n",
       "      <td>https://www.leafly.com/hybrid/yummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>3441</td>\n",
       "      <td>https://www.leafly.com/sativa/zamaldelica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>3442</td>\n",
       "      <td>https://www.leafly.com/hybrid/zardde-gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>3443</td>\n",
       "      <td>https://www.leafly.com/hybrid/zeitgeist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>3444</td>\n",
       "      <td>https://www.leafly.com/hybrid/zelda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>3445</td>\n",
       "      <td>https://www.leafly.com/sativa/zellys-gift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>3446</td>\n",
       "      <td>https://www.leafly.com/hybrid/zen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950</th>\n",
       "      <td>3447</td>\n",
       "      <td>https://www.leafly.com/hybrid/zerculese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>3448</td>\n",
       "      <td>https://www.leafly.com/sativa/zeta-sage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2952</th>\n",
       "      <td>3449</td>\n",
       "      <td>https://www.leafly.com/hybrid/zeus-og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2953</th>\n",
       "      <td>3450</td>\n",
       "      <td>https://www.leafly.com/indica/zkittlez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2954</th>\n",
       "      <td>3451</td>\n",
       "      <td>https://www.leafly.com/indica/zombie-kush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2955</th>\n",
       "      <td>3452</td>\n",
       "      <td>https://www.leafly.com/indica/zombie-og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>3453</td>\n",
       "      <td>https://www.leafly.com/indica/zoom-pie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>3454</td>\n",
       "      <td>https://www.leafly.com/hybrid/hai-fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>3455</td>\n",
       "      <td>https://www.leafly.com/hybrid/test1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>3456</td>\n",
       "      <td>https://www.leafly.com/indica/a4de22ba-0b77-4a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>3457</td>\n",
       "      <td>https://www.leafly.com/hybrid/test1-f4c2596aa9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>3458</td>\n",
       "      <td>https://www.leafly.com/hybrid/alenuihaha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>3459</td>\n",
       "      <td>https://www.leafly.com/strain/details</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2963 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                                url\n",
       "0         0               https://www.leafly.com/hybrid/100-og\n",
       "1         1       https://www.leafly.com/hybrid/98-white-widow\n",
       "2         2                 https://www.leafly.com/sativa/1024\n",
       "3         3           https://www.leafly.com/hybrid/12-year-og\n",
       "4         4             https://www.leafly.com/hybrid/13-dawgs\n",
       "5         5                   https://www.leafly.com/hybrid/22\n",
       "6         6             https://www.leafly.com/hybrid/24k-gold\n",
       "7         7           https://www.leafly.com/indica/3-bears-og\n",
       "8        16              https://www.leafly.com/hybrid/3-kings\n",
       "9        17               https://www.leafly.com/indica/303-og\n",
       "10       18               https://www.leafly.com/sativa/3d-cbd\n",
       "11       19             https://www.leafly.com/indica/3x-crazy\n",
       "12       20  https://www.leafly.com/hybrid/3rd-coast-panama...\n",
       "13       21             https://www.leafly.com/hybrid/501st-og\n",
       "14       22             https://www.leafly.com/hybrid/541-kush\n",
       "15       23          https://www.leafly.com/indica/5th-element\n",
       "16       24         https://www.leafly.com/hybrid/707-headband\n",
       "17       25        https://www.leafly.com/hybrid/707-truthband\n",
       "18       26          https://www.leafly.com/indica/8-ball-kush\n",
       "19       27               https://www.leafly.com/indica/818-og\n",
       "20       28               https://www.leafly.com/indica/831-og\n",
       "21       29                  https://www.leafly.com/hybrid/840\n",
       "22       30       https://www.leafly.com/indica/9-pound-hammer\n",
       "23       31             https://www.leafly.com/indica/91-krypt\n",
       "24       32                https://www.leafly.com/hybrid/92-og\n",
       "25       33                  https://www.leafly.com/indica/999\n",
       "26       34                 https://www.leafly.com/indica/a-10\n",
       "27       35                https://www.leafly.com/hybrid/a-dub\n",
       "28       36              https://www.leafly.com/hybrid/a-train\n",
       "29       37                 https://www.leafly.com/hybrid/acdc\n",
       "...     ...                                                ...\n",
       "2933   3422               https://www.leafly.com/indica/xxx-og\n",
       "2934   3423               https://www.leafly.com/sativa/xanadu\n",
       "2935   3432             https://www.leafly.com/sativa/y-griega\n",
       "2936   3433               https://www.leafly.com/hybrid/yem-og\n",
       "2937   3434              https://www.leafly.com/indica/yeti-og\n",
       "2938   3435              https://www.leafly.com/indica/yoda-og\n",
       "2939   3436          https://www.leafly.com/indica/yodas-brain\n",
       "2940   3437          https://www.leafly.com/hybrid/yogi-diesel\n",
       "2941   3438           https://www.leafly.com/indica/yolo-berry\n",
       "2942   3439             https://www.leafly.com/indica/yumboldt\n",
       "2943   3440                https://www.leafly.com/hybrid/yummy\n",
       "2944   3441          https://www.leafly.com/sativa/zamaldelica\n",
       "2945   3442          https://www.leafly.com/hybrid/zardde-gold\n",
       "2946   3443            https://www.leafly.com/hybrid/zeitgeist\n",
       "2947   3444                https://www.leafly.com/hybrid/zelda\n",
       "2948   3445          https://www.leafly.com/sativa/zellys-gift\n",
       "2949   3446                  https://www.leafly.com/hybrid/zen\n",
       "2950   3447            https://www.leafly.com/hybrid/zerculese\n",
       "2951   3448            https://www.leafly.com/sativa/zeta-sage\n",
       "2952   3449              https://www.leafly.com/hybrid/zeus-og\n",
       "2953   3450             https://www.leafly.com/indica/zkittlez\n",
       "2954   3451          https://www.leafly.com/indica/zombie-kush\n",
       "2955   3452            https://www.leafly.com/indica/zombie-og\n",
       "2956   3453             https://www.leafly.com/indica/zoom-pie\n",
       "2957   3454          https://www.leafly.com/hybrid/hai-fantasy\n",
       "2958   3455                https://www.leafly.com/hybrid/test1\n",
       "2959   3456  https://www.leafly.com/indica/a4de22ba-0b77-4a...\n",
       "2960   3457  https://www.leafly.com/hybrid/test1-f4c2596aa9...\n",
       "2961   3458           https://www.leafly.com/hybrid/alenuihaha\n",
       "2962   3459              https://www.leafly.com/strain/details\n",
       "\n",
       "[2963 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2963"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(url_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "#breaking down scraping into smaller buckets\n",
    "\n",
    "urls_to_200 = urls_df['url'][:200]          #soups\n",
    "urls_to_700 = urls_df['url'][200:700]       #soups_to_700\n",
    "urls_to_1200 = urls_df['url'][700:1200]     #soups_to_1200\n",
    "urls_to_1700 = urls_df['url'][1200:1700]    #soups_to_1700\n",
    "urls_to_2200 = urls_df['url'][1700:2200]    #soups_to_2200\n",
    "urls_to_2700 = urls_df['url'][2200:2700]    #soups_to_2700\n",
    "urls_to_end = urls_df['url'][2700:]         #soups_to_end\n",
    "\n",
    "#scraping all at once\n",
    "urls_total = urls_df['url']                 #soups_total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape individual strain pages\n",
    "\n",
    "soups_total = []\n",
    "\n",
    "for url in urls_total:\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    soups_total.append(soup)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"soups_total.html\", \"w\") as file:\n",
    "    file.write(str(soups_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14908"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(med)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Features From Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a6c3f023374c0d825e9d49c06f3f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3460), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a3628ebd074897b6e8c3ccb63c08a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3460), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fccde5e506c04026a0a387aa869abbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3460), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d418bbe4180749be8a6f08c17f9743eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3460), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use this one\n",
    "\n",
    "#collect positive effects\n",
    "\n",
    "effect = []\n",
    "filename1 = \"effect.csv\"\n",
    "\n",
    "for i in tqdm(range(0, len(soups_total))): \n",
    "    names = []\n",
    "    cont = soups_total[i].find(\"a\",{\"class\":\"active\"})  \n",
    "    names.append(cont)\n",
    "    try:\n",
    "        for name in names:\n",
    "            strain_name = name.get('href') \n",
    "            strain = strain_name.split('/')\n",
    "        div = soups_total[i].find('div', {'id': 'effects-tab-content'})\n",
    "        first_child = div.findChildren('div', {'class': \"histogram-label\"})\n",
    "        try:\n",
    "            if len(first_child) == 5:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                    first_child[2].text, first_child[3].text, \n",
    "                        first_child[4].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 4:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                          first_child[2].text, first_child[3].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 3:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                          first_child[2].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 2:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 1:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            else:\n",
    "                key = strain[2]\n",
    "                values = None\n",
    "                par = {key:values}       \n",
    "        except:\n",
    "            key = strain[2]\n",
    "            values = None\n",
    "            par = {key:values}\n",
    "    except:\n",
    "        key = strain[2]\n",
    "        values = None\n",
    "        par = {key:values}\n",
    "    \n",
    "        \n",
    "    effect.append(par)\n",
    "\n",
    "df_effect = pd.DataFrame(effect)\n",
    "df_effect.to_csv(filename1)\n",
    "\n",
    "#collect medical attributes\n",
    "\n",
    "med = []\n",
    "filename2 = \"med.csv\"\n",
    "\n",
    "for i in tqdm(range(0, len(soups_total))): \n",
    "    names = []\n",
    "    cont = soups_total[i].find(\"a\",{\"class\":\"active\"})  \n",
    "    names.append(cont)\n",
    "    try:\n",
    "        for name in names:\n",
    "            strain_name = name.get('href') \n",
    "            strain = strain_name.split('/')\n",
    "        div = soups_total[i].find('div', {'id': 'medical-tab-content'})\n",
    "        first_child = div.findChildren('div', {'class': \"histogram-label\"})\n",
    "        try:\n",
    "            if len(first_child) == 5:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                    first_child[2].text, first_child[3].text, \n",
    "                        first_child[4].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 4:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                          first_child[2].text, first_child[3].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 3:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                          first_child[2].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 2:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 1:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            else:\n",
    "                key = strain[2]\n",
    "                values = None\n",
    "                par = {key:values}       \n",
    "        except:\n",
    "            key = strain[2]\n",
    "            values = None\n",
    "            par = {key:values}\n",
    "    except:\n",
    "        key = strain[2]\n",
    "        values = None\n",
    "        par = {key:values}\n",
    "    \n",
    "        \n",
    "    med.append(par)\n",
    "\n",
    "df_med = pd.DataFrame(med)\n",
    "df_med.to_csv(filename2)\n",
    "\n",
    "#collect negative attributes\n",
    "\n",
    "neg = []\n",
    "filename3 = \"neg.csv\"\n",
    "\n",
    "for i in tqdm(range(0, len(soups_total))): \n",
    "    names = []\n",
    "    cont = soups_total[i].find(\"a\",{\"class\":\"active\"})  \n",
    "    names.append(cont)\n",
    "    try:\n",
    "        for name in names:\n",
    "            strain_name = name.get('href') \n",
    "            strain = strain_name.split('/')\n",
    "        div = soups_total[i].find('div', {'id': 'negatives-tab-content'})\n",
    "        first_child = div.findChildren('div', {'class': \"histogram-label\"})\n",
    "        try:\n",
    "            if len(first_child) == 5:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                    first_child[2].text, first_child[3].text, \n",
    "                        first_child[4].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 4:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                          first_child[2].text, first_child[3].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 3:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                          first_child[2].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 2:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 1:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            else:\n",
    "                key = strain[2]\n",
    "                values = None\n",
    "                par = {key:values}       \n",
    "        except:\n",
    "            key = strain[2]\n",
    "            values = None\n",
    "            par = {key:values}\n",
    "    except:\n",
    "        key = strain[2]\n",
    "        values = None\n",
    "        par = {key:values}\n",
    "    \n",
    "        \n",
    "    neg.append(par)\n",
    "\n",
    "df_neg = pd.DataFrame(neg)\n",
    "df_neg.to_csv(filename3)\n",
    "\n",
    "#collect flavors\n",
    "\n",
    "flavors = []\n",
    "filename4 = \"flavors.csv\"\n",
    "\n",
    "for i in tqdm(range(0, len(soups_total))): \n",
    "    names = []\n",
    "    cont = soups_total[i].find(\"a\",{\"class\":\"active\"})  \n",
    "    names.append(cont)\n",
    "    try:\n",
    "        for name in names:\n",
    "            strain_name = name.get('href')\n",
    "            strain = strain_name.split('/')\n",
    "        first_child = soups_total[i].findAll('div',attrs={\"class\" : \"flavor-name\"})\n",
    "        try:\n",
    "            if len(first_child) == 3:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                        first_child[2].text]\n",
    "                par = {key:values}\n",
    "            elif len(first_child) == 2:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text]\n",
    "                par = {key:values}\n",
    "            elif len(first_child) == 1:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text]\n",
    "                par = {key:values}\n",
    "            else:\n",
    "                key = strain[2]\n",
    "                values = None\n",
    "                par = {key:values}       \n",
    "        except:\n",
    "            key = strain[2]\n",
    "            values = None\n",
    "            par = {key:values}\n",
    "    except:\n",
    "        key = strain[2]\n",
    "        values = None\n",
    "        par = {key:values}\n",
    "    \n",
    "        \n",
    "    flavors.append(par)\n",
    "\n",
    "df_flavors = pd.DataFrame(flavors)\n",
    "df_flavors.to_csv(filename4)  \n",
    "\n",
    "#collect parents of strains\n",
    "\n",
    "parents = []\n",
    "\n",
    "filename5 = 'parents.csv'\n",
    "\n",
    "for i in tqdm(range(0, len(soups_total))): \n",
    "    children = soups_total[i].findAll('div',attrs={\"class\" : \"strain-tile-footer\"})\n",
    "    try:\n",
    "        if len(children) == 3:\n",
    "            key = children[0].text\n",
    "            values = [children[1].text, children[2].text]\n",
    "            par = {key:values}\n",
    "        elif len(children) == 2:\n",
    "            key = children[0].text\n",
    "            values = children[1].text\n",
    "            par = {key:values}        \n",
    "        else:\n",
    "            key = children[0].text\n",
    "            values = None\n",
    "            par = {key:values}\n",
    "    except:\n",
    "        None\n",
    "        #print(\"can't find that page\")\n",
    "    \n",
    "    parents.append(par)\n",
    "   \n",
    "\n",
    "df_parents = pd.DataFrame(parents)\n",
    "df_parents.to_csv(filename5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get review numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "category_tokens = ['hyrid', 'indica', 'sativa']\n",
    "\n",
    "flavor_tokens = ['Ammonia', 'Apple', 'Apricot', 'Berry' \n",
    "                 'Blue Cheese', 'Blueberry', 'Butter', \n",
    "                 'Cheese', 'Chemical', 'Chestnut', 'Citrus',\n",
    "                 'Coffee', 'Diesel', 'Earthy', 'Flowery',\n",
    "                 'Grape', 'Grapefruit', 'Honey', 'Lavender',\n",
    "                 'Lemon', 'Lime', 'Mango', 'Menthol', 'Mint',\n",
    "                 'Nutty', 'Orange', 'Peach', 'Pear', 'Pepper',\n",
    "                 'Pine', 'Pineapple', 'Plum', 'Pungent', 'Rose', \n",
    "                 'Sage', 'Skunk', 'Spicy/Herbal', 'Strawberry',\n",
    "                 'Sweet', 'Tar', 'Tea', 'Tobacco', 'Tree Fruit',\n",
    "                 'Tropical', 'Vanilla', 'Violet', 'Woody']\n",
    "\n",
    "effect_tokens = ['Anxious', 'Aroused', 'Creative', 'Energetic',\n",
    "                 'Euphoric', 'Focused', 'Giggly', 'Happy', \n",
    "                 'Hungry', 'Relaxed', 'Sleepy', 'Talkative',\n",
    "                 'Tingly', 'Uplifted']\n",
    "\n",
    "medical_tokens = ['Cramps', 'Depression', 'Eye Pressure', 'Fatigue',\n",
    "                  'Headaches', 'Inflammation', 'Insomnia', \n",
    "                  'Lack Of Appetite', 'Muscle Spasms', 'Nausea',\n",
    "                  'Pain Seizures', 'Spasticity', 'Stress', 'ADD/ADHD',\n",
    "                  \"Alzheimer's\", 'Anorexia', 'Anxiety', 'Arthritis',\n",
    "                  'Asthma', 'Bipolar Disorder', 'Cachexia', 'Cancer',\n",
    "                  \"Crohn's Disease\", 'Epilepsy', 'Fibromyalgia', \n",
    "                  'Gastrointestinal Disorder', 'Glaucoma', 'HIV/AIDS',\n",
    "                  'Hypertension', 'Migraines', 'Multiple Sclerosis',\n",
    "                  'Muscular Dystrophy', 'PMS', 'PTSD', \"Parkinson's\",\n",
    "                  'Phantom Limb Pain', 'Spinal Cord Injury',\n",
    "                  'Tinnitus', \"Tourette's Syndrome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = '/indica/zombie-og'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/indica/zombie-og'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain = string.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'indica', 'zombie-og']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'indica'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strain[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zombie-og']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #original code, revised but saving for now\n",
    "\n",
    "# #positive effects\n",
    "\n",
    "# effect = []\n",
    "# filename1 = \"effect_total.csv\"\n",
    "\n",
    "# for i in tqdm(range(0, len(soups_total))): \n",
    "#     names = []\n",
    "#     cont = soups_total[i].find(\"a\",{\"class\":\"active\"})  \n",
    "#     names.append(cont)\n",
    "#     try:\n",
    "#         for name in names:\n",
    "#             strain_name = name.get('href') \n",
    "#             strain = strain_name.split('/')\n",
    "#         div = soups_total[i].find('div', {'id': 'effects-tab-content'})\n",
    "#         first_child = div.findChildren('div', {'class': \"histogram-label\"})\n",
    "#         for child in first_child:\n",
    "#             effect.append({strain[2]: child.text}) \n",
    "#     except:\n",
    "#         effect.append({strain[2]:None})\n",
    "\n",
    "\n",
    "# df_eff_total = pd.DataFrame(effect)\n",
    "# df_eff_total.to_csv(filename1)\n",
    "\n",
    "# #medical benefits\n",
    "\n",
    "# med = []\n",
    "# filename3 = \"med_total.csv\"\n",
    "\n",
    "# for i in tqdm(range(0, len(soups_total))):\n",
    "#     names = []\n",
    "#     cont = soups_total[i].find(\"a\",{\"class\":\"active\"})  \n",
    "#     names.append(cont)\n",
    "#     try:\n",
    "#         for name in names:\n",
    "#             strain_name = name.get('href')\n",
    "#             strain = strain_name.split('/')\n",
    "#         div = soups_total[i].find('div', {'id': 'medical-tab-content'})\n",
    "#         first_child = div.findChildren('div', {'class': 'histogram-label'})\n",
    "#         for child in first_child:\n",
    "#             med.append({strain[2]: child.text})  \n",
    "#     except:\n",
    "#         med.append({strain[2]:None})\n",
    "\n",
    "# df_med_total = pd.DataFrame(med)\n",
    "# df_med_total.to_csv(filename3) \n",
    "\n",
    "        \n",
    "# #negative effects\n",
    "\n",
    "# neg = []\n",
    "# filename5 = \"neg_total.csv\"\n",
    "        \n",
    "# for i in tqdm(range(0, len(soups_total))): \n",
    "#     names = []\n",
    "#     cont = soups_total[i].find(\"a\",{\"class\":\"active\"})  \n",
    "#     names.append(cont)\n",
    "#     try:\n",
    "#         for name in names:\n",
    "#             strain_name = name.get('href')\n",
    "#             strain = strain_name.split('/')\n",
    "#         div = soups_total[i].find('div', {'id': 'negatives-tab-content'})\n",
    "#         first_child = div.findChildren('div', {'class': 'histogram-label'})\n",
    "#         for child in first_child:\n",
    "#             neg.append({strain[2]: child.text}) \n",
    "#     except:\n",
    "#         neg.append({strain[2]:None})\n",
    "\n",
    "\n",
    "# df_neg_total = pd.DataFrame(neg)\n",
    "# df_neg_total.to_csv(filename5)\n",
    "\n",
    "# #collect flavors\n",
    "\n",
    "# flavors = []\n",
    "# filename7 = \"flavors_total.csv\"\n",
    "\n",
    "# for i in tqdm(range(0, len(soups_total))): \n",
    "#     names = []\n",
    "#     cont = soups_total[i].find(\"a\",{\"class\":\"active\"})  \n",
    "#     names.append(cont)\n",
    "#     try:\n",
    "#         for name in names:\n",
    "#             strain_name = name.get('href')\n",
    "#             strain = strain_name.split('/')\n",
    "#         children = soups_total[i].findAll('div',attrs={\"class\" : \"flavor-name\"})\n",
    "#         for child in children:\n",
    "#             flavors.append({strain[2]: child.text})\n",
    "#     except:\n",
    "#         flavors.append({strain[2]:None})\n",
    "\n",
    "# df_flavors_total = pd.DataFrame(flavors)\n",
    "# df_flavors_total.to_csv(filename7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # trying to put everything together for final data csv\n",
    "# filename1 = \"cannabis_data.csv\"\n",
    "\n",
    "# #for attribute data\n",
    "# data = []\n",
    "\n",
    "# #parse attributes from scraped webpages\n",
    "# for i in range(0, len(soups_total)):\n",
    "    \n",
    "#     effect = []\n",
    "#     med = []\n",
    "#     neg = []\n",
    "#     flavors = []\n",
    "    \n",
    "#     #get strain name for dictionary\n",
    "#     names = []\n",
    "#     cont = soups_total[i].find(\"a\",{\"class\":\"active\"})  \n",
    "#     names.append(cont)\n",
    "#     for name in names:\n",
    "#         try:\n",
    "#             strain_name = name.get('href') \n",
    "#             strain = strain_name.split('/')\n",
    "#         except:\n",
    "#             strain = None\n",
    "        \n",
    "#     #get list of effects attributes\n",
    "#         try:\n",
    "#             div = soups_total[i].find('div', {'id': 'effects-tab-content'})\n",
    "#             first_child = div.findChildren('div', {'class': 'histogram-item-wrapper'})\n",
    "#             for effect in first_child:\n",
    "#                 effect.append(effect.text) \n",
    "#         except:\n",
    "#             effect.append(None)\n",
    "#     #get list of medical attributes\n",
    "#         try:\n",
    "#             div = soups_total[i].find('div', {'id': 'medical-tab-content'})\n",
    "#             first_child = div.findChildren('div', {'class': 'histogram-item-wrapper'})\n",
    "#             for med in first_child:\n",
    "#                 med.append(med.text)  \n",
    "#         except:\n",
    "#             med.append(None)\n",
    "#     #get list of negative attributes\n",
    "#         try:\n",
    "#             div = soups_total[i].find('div', {'id': 'negatives-tab-content'})\n",
    "#             first_child = div.findChildren('div', {'class': 'histogram-item-wrapper'})\n",
    "#             for neg in first_child:\n",
    "#                 neg.append(neg.text) \n",
    "#         except:\n",
    "#             neg.append(None)\n",
    "#     #get list of strain flavors\n",
    "#         try:\n",
    "#             children = soups_total[i].findAll('div',attrs={\"class\" : \"flavor-name\"})\n",
    "#             for flavor in children:\n",
    "#                 flavors.append(flavor.text)\n",
    "#         except:\n",
    "#             flavors.append(None)\n",
    "\n",
    "# #create dictionary with all attributes\n",
    "# data.append({strain[2]: {'effects': effect, 'medical': med, 'negative': neg, \n",
    "#                          'flavors': flavors}}) \n",
    "\n",
    "# #create dataframe and csv file\n",
    "# df = pd.DataFrame(data)\n",
    "# df.to_csv(filename1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
